{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Calculate TF-IDF using functions and broadcast variables.</h1>\n",
    "<p>TF-IDF or text frequency, inverse document frequency, is a way of rating the importance of a word in a particular document.  It is used in search engines, text vectorizers, just to name a few.\n",
    "\n",
    "To do so, we'll revisit the text sorting example from before, but we'll introduce a few new concepts like leveraging functions, and using broadcast variables.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get some data</h2>\n",
    "<p>Spark is made for looking at data....lots of data.  Since we're running locally, we're restricted to the memory of our laptops and only a few cores.  As such we'll use small data as an illustrative example from sklearn.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well i'm not sure about the story nad it did seem biased. What\n",
      "I disagree with is your statement that the U.S. Media is out to\n",
      "ruin Israels reputation. That is rediculous. The U.S. media is\n",
      "the most pro-israeli media in the world. Having lived in Europe\n",
      "I realize that incidences such as the one described in the\n",
      "letter have occured. The U.S. media as a whole seem to try to\n",
      "ignore them. The U.S. is subsidizing Israels existance and the\n",
      "Europeans are not (at least not to the same degree). So I think\n",
      "that might be a reason they report more clearly on the\n",
      "atrocities.\n",
      "\tWhat is a shame is that in Austria, daily reports of\n",
      "the inhuman acts commited by Israeli soldiers and the blessing\n",
      "received from the Government makes some of the Holocaust guilt\n",
      "go away. After all, look how the Jews are treating other races\n",
      "when they got power. It is unfortunate.\n",
      "\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print dataset.data[0]\n",
    "\n",
    "print len(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>SHUT UP AND START THE SPARK!</h2>\n",
    "<p>Gotcha.  Let''s start by creating our first rdd.  To do so, we use the\n",
    "`sc.parralllelize` command</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(dataset.data)\n",
    "print type(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Now for the word count</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'the', 104952), (u'to', 52420), (u'of', 46651), (u'a', 42348), (u'and', 41621), (u'in', 30324), (u'is', 29958), (u'i', 27792), (u'that', 26700), (u'it', 20382)]\n"
     ]
    }
   ],
   "source": [
    "terms = rdd.flatMap(lambda text: text.split())\\\n",
    "            .map(lambda word: (word.strip(\".,-;?\").lower(), 1))\\\n",
    "            .reduceByKey(lambda a, b: a+b)\\\n",
    "            .sortBy(lambda x: x[1], ascending=False)\\\n",
    "            .take(10)\n",
    "            \n",
    "print terms"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
